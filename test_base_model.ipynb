{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4cb2ef6-7e27-47a7-9a35-c43f6a6fd4ab",
   "metadata": {},
   "source": [
    "### Base Model No Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e758ee56-8ab6-46d2-b6df-ed573ef74f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec3fa8bad3644ec843b939798a96e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./models/CodeLlama-7b-Python-HF\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./models/CodeLlama-7b-Python-HF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c65998-b072-46c3-83c1-470464e306c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a coding AI\\n\\n### Input:\\nPlease explain the reasoning behind the following solution and \\nprovide code in python: Given a string `s`, return the longest palindromic \\nsubstring in `s`. **Example 1:** **Input:** s = \"babad \" **Output:** \"bab \" \\n**Explanation:** \"aba \" is also a valid answer. **Example 2:** \\n**Input:** s = \"cbbd \" **Output:** \"bb \" \\n**Constraints:** * `1 <= s.length <= 1000` * `s` consist of only digits \\nand English letters.\\n\\n### Response:\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_format = \"\"\"{system_prompt}\n",
    "\n",
    "### Input:\n",
    "{question}\n",
    "\n",
    "### Response:\\n\"\"\"\n",
    "\n",
    "system = \"You are a coding AI\"\n",
    "prompt = \"\"\"Please explain the reasoning behind the following solution and \n",
    "provide code in python: Given a string `s`, return the longest palindromic \n",
    "substring in `s`. **Example 1:** **Input:** s = \"babad \" **Output:** \"bab \" \n",
    "**Explanation:** \"aba \" is also a valid answer. **Example 2:** \n",
    "**Input:** s = \"cbbd \" **Output:** \"bb \" \n",
    "**Constraints:** * `1 <= s.length <= 1000` * `s` consist of only digits \n",
    "and English letters.\"\"\"\n",
    "\n",
    "alpaca_format = alpaca_format.format(system_prompt=system, question=prompt)\n",
    "alpaca_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8266a19c-d9d4-4485-872c-0c4a47a677db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(alpaca_format, return_tensors=\"pt\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c002ea9e-794b-40e3-b000-6d9ded9d72d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(input_ids, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82055fe4-de02-4f67-9f3a-bb80094ca4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n```python\\nclass Solution:\\n    def longestPalindrome(self, s: str) -> str:\\n        if len(s) <= 1:\\n            return s\\n        longest = ''\\n        for i in range(len(s)):\\n            odd = self.helper(s, i, i)\\n            even = self.helper(s, i, i+1)\\n            longest = max(longest, odd, even, key=len)\\n        return longest\\n    \\n    def helper(self, s, left, right):\\n        while left >= 0\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filling = tokenizer.batch_decode(generated_ids[:, input_ids.shape[1]:], skip_special_tokens = True)[0]\n",
    "filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9301dd-5895-4308-b2f9-2ba0d5a63df6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```python\n",
      "class Solution:\n",
      "    def longestPalindrome(self, s: str) -> str:\n",
      "        if len(s) <= 1:\n",
      "            return s\n",
      "        longest = ''\n",
      "        for i in range(len(s)):\n",
      "            odd = self.helper(s, i, i)\n",
      "            even = self.helper(s, i, i+1)\n",
      "            longest = max(longest, odd, even, key=len)\n",
      "        return longest\n",
      "    \n",
      "    def helper(self, s, left, right):\n",
      "        while left >= 0\n"
     ]
    }
   ],
   "source": [
    "print(filling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23372f66-7aae-4ede-a089-4bb140e581e4",
   "metadata": {},
   "source": [
    "### Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2fae08-317a-4920-8408-e02206539e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5f0739babe42dfb76533d00672e057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./finetuned_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e71887d-3051-4ddf-8236-4e124f7af8db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a coding AI\\n\\n### Input:\\nPlease explain the reasoning behind the following solution and \\nprovide code in python: Given a string `s`, return the longest palindromic \\nsubstring in `s`. **Example 1:** **Input:** s = \"babad \" **Output:** \"bab \" \\n**Explanation:** \"aba \" is also a valid answer. **Example 2:** \\n**Input:** s = \"cbbd \" **Output:** \"bb \" \\n**Constraints:** * `1 <= s.length <= 1000` * `s` consist of only digits \\nand English letters.\\n\\n### Response:\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_format = \"\"\"{system_prompt}\n",
    "\n",
    "### Input:\n",
    "{question}\n",
    "\n",
    "### Response:\\n\"\"\"\n",
    "\n",
    "system = \"You are a coding AI\"\n",
    "prompt = \"\"\"Please explain the reasoning behind the following solution and \n",
    "provide code in python: Given a string `s`, return the longest palindromic \n",
    "substring in `s`. **Example 1:** **Input:** s = \"babad \" **Output:** \"bab \" \n",
    "**Explanation:** \"aba \" is also a valid answer. **Example 2:** \n",
    "**Input:** s = \"cbbd \" **Output:** \"bb \" \n",
    "**Constraints:** * `1 <= s.length <= 1000` * `s` consist of only digits \n",
    "and English letters.\"\"\"\n",
    "\n",
    "alpaca_format = alpaca_format.format(system_prompt=system, question=prompt)\n",
    "alpaca_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5430e44f-b2db-433d-ac58-dbd7c9565f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(alpaca_format, return_tensors=\"pt\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d091933b-a68d-48e1-b9ca-3ed44e5e2bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(input_ids, max_new_tokens=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904a9083-938d-4507-b509-bd02a93cfb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filling = tokenizer.batch_decode(generated_ids[:, input_ids.shape[1]:], skip_special_tokens = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b8209b-6c89-4d4b-b49a-7d952f6652a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Explanation\n",
      " The algorithm uses a sliding window approach to find the longest palindromic substring. It iterates through the string with two pointers, `left` and `right`, starting from the beginning and the end of the string, respectively. It checks if the substring formed by the current indices is a palindrome. If it is, it updates the longest palindromic substring found so far. If not, it moves the `left` pointer to the right and checks again. This process continues until the pointers cross each other, at which point the longest palindromic substring is found.\n",
      "\n",
      "### Code\n",
      "```python\n",
      "def longest_palindromic_substring(s):\n",
      "    n = len(s)\n",
      "    longest = \"\"\n",
      "    for i in range(n):\n",
      "        for j in range(i + 1, n + 1):\n",
      "            substring = s[i:j]\n",
      "            if substring == substring[::-1]:\n",
      "                longest = max(longest, substring)\n",
      "    return longest\n",
      "```\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(filling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48878236-9e73-4d01-b678-fcd2865de82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
